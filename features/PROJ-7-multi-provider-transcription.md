# PROJ-7: Multi-Provider Transkriptions-Engine

## Status: üîµ Planned

## Beschreibung
Erm√∂glicht das parallele Transkribieren von Audio-Files mit bis zu 9 verschiedenen Transkriptions-Providern. User w√§hlen Provider aus, konfigurieren Features (Speaker Diarization, Timestamps, Confidence) und starten Jobs. System verwaltet API-Requests, Progress-Tracking und Error-Handling.

## Unterst√ºtzte Provider
1. **OpenAI Whisper** - whisper-1 model
2. **AssemblyAI** - Best, Nano models
3. **Google Speech-to-Text** - V2 API
4. **AWS Transcribe** - Standard, Medical
5. **ElevenLabs** - Speech-to-Text API
6. **Deepgram** - Nova-2, Whisper models
7. **Gladia** - Fast, Accurate models
8. **Speechmatics** - Batch, Real-time
9. **OpenRouter** - Aggregator mit Zugang zu vielen STT-Models

## User Stories

### Provider-Auswahl
- Als **User** m√∂chte ich aus 9 Providern ausw√§hlen k√∂nnen, um verschiedene Engines zu testen
- Als **User** m√∂chte ich mehrere Provider gleichzeitig ausw√§hlen k√∂nnen, um Ergebnisse zu vergleichen
- Als **User** m√∂chte ich f√ºr jeden Provider sehen welche Features unterst√ºtzt werden, um die richtige Wahl zu treffen
- Als **User** m√∂chte ich meine API-Keys f√ºr jeden Provider hinterlegen k√∂nnen, um die Services nutzen zu k√∂nnen

### Transkriptions-Features
- Als **User** m√∂chte ich Speaker Diarization aktivieren k√∂nnen, um zu sehen wer wann spricht
- Als **User** m√∂chte ich Timestamps (Wort-/Satz-Level) aktivieren k√∂nnen, um zeitliche Navigation zu haben
- Als **User** m√∂chte ich Confidence Scores sehen, um die Qualit√§t einzusch√§tzen
- Als **User** m√∂chte ich Sprache/Language ausw√§hlen k√∂nnen, um bessere Ergebnisse zu erhalten

### Job-Processing
- Als **User** m√∂chte ich den Transkriptions-Progress in Echtzeit sehen (f√ºr kleine Files < 5 Min), um zu wissen wie lange es noch dauert
- Als **User** m√∂chte ich eine Notification erhalten wenn gro√üe Files (> 5 Min) fertig sind, um nicht warten zu m√ºssen
- Als **User** m√∂chte ich laufende Jobs abbrechen k√∂nnen, um Kosten zu sparen bei falscher Konfiguration
- Als **User** m√∂chte ich Fehler-Details sehen wenn ein Provider-Job fehlschl√§gt, um das Problem zu verstehen

### API-Key Management
- Als **User** m√∂chte ich meine API-Keys sicher speichern k√∂nnen, um sie nicht bei jedem Job neu eingeben zu m√ºssen
- Als **User** m√∂chte ich API-Keys pro Provider verwalten (hinzuf√ºgen, √§ndern, l√∂schen), um Flexibilit√§t zu haben
- Als **User** m√∂chte ich testen k√∂nnen ob meine API-Keys funktionieren, bevor ich einen Job starte

## Acceptance Criteria

### Provider-Auswahl Screen (nach Upload)
- [ ] Screen zeigt: "W√§hle Transkriptions-Provider"
- [ ] Grid/Liste mit 9 Provider-Cards:
  - [ ] Provider-Name + Logo
  - [ ] Status: "API-Key vorhanden ‚úì" oder "API-Key fehlt ‚ö†"
  - [ ] Checkbox: Provider ausw√§hlen
  - [ ] Button: "API-Key verwalten"
  - [ ] Info-Icon: Zeigt unterst√ºtzte Features (Speaker Diarization, Timestamps, etc.)
- [ ] User kann 1-9 Provider ausw√§hlen
- [ ] Button: "Weiter zu Konfiguration" (enabled nur wenn min. 1 Provider ausgew√§hlt)

### API-Key Management Modal
- [ ] Click auf "API-Key verwalten" √∂ffnet Modal f√ºr Provider X
- [ ] Modal zeigt:
  - [ ] Input-Feld: "API-Key" (password-type, masked)
  - [ ] Link: "Wo finde ich meinen API-Key?" ‚Üí Provider-Docs
  - [ ] Button: "Key testen" (validiert Key mit Test-Request)
  - [ ] Button: "Speichern"
  - [ ] Button: "L√∂schen" (nur wenn Key bereits gespeichert)
- [ ] API-Keys werden encrypted in Database gespeichert (AES-256)
- [ ] Nach "Speichern": Success-Message "API-Key f√ºr [Provider] gespeichert"
- [ ] Test-Request:
  - [ ] System sendet kleinen Test-Request an Provider-API
  - [ ] Success: "‚úì API-Key funktioniert!"
  - [ ] Error: "‚úó API-Key ung√ºltig oder Quota √ºberschritten"

### Transkriptions-Konfiguration Screen
- [ ] Screen zeigt ausgew√§hlte Provider (z.B. "3 Provider ausgew√§hlt: OpenAI Whisper, AssemblyAI, Deepgram")
- [ ] Global Settings (gelten f√ºr alle Provider):
  - [ ] Dropdown: "Sprache/Language" (Auto-Detect, Deutsch, Englisch, Spanisch, etc.)
  - [ ] Checkbox: "Speaker Diarization aktivieren" (nur f√ºr Stereo-Files)
  - [ ] Checkbox: "Word-Level Timestamps"
  - [ ] Checkbox: "Confidence Scores"
- [ ] Pro-Provider Settings (Advanced):
  - [ ] Collapsible-Section pro Provider
  - [ ] Model-Auswahl (falls Provider mehrere Models hat, z.B. AssemblyAI Best vs Nano)
  - [ ] Custom Parameters (JSON-Input f√ºr Advanced Users)
- [ ] Cost Estimation (optional):
  - [ ] Zeige gesch√§tzte Kosten pro Provider (basierend auf Audio-Dauer)
  - [ ] Total: "Gesch√§tzte Kosten: ~$X.XX"
- [ ] Button: "Transkription starten"

### Job-Processing (Echtzeit f√ºr kleine Files < 5 Min)
- [ ] Nach "Transkription starten": Processing-Screen
- [ ] Screen zeigt Liste der Provider-Jobs:
  - [ ] Provider-Name
  - [ ] Status: "Queued" ‚Üí "Processing" ‚Üí "Completed" / "Failed"
  - [ ] Progress-Bar (0-100%)
  - [ ] Elapsed Time
  - [ ] Button: "Abbrechen" (f√ºr laufende Jobs)
- [ ] Jobs laufen parallel (max 9 concurrent API-Requests)
- [ ] Progress-Tracking:
  - [ ] Bei Providern mit Polling-API: Polling alle 2-5 Sekunden
  - [ ] Bei Providern mit Webhook: Webhook-Endpoint f√ºr Completion-Notification
- [ ] Nach Completion aller Jobs:
  - [ ] Success-Screen: "Transkription abgeschlossen! X von Y Jobs erfolgreich."
  - [ ] Button: "Ergebnisse vergleichen" ‚Üí PROJ-8

### Job-Processing (Async f√ºr gro√üe Files > 5 Min)
- [ ] Nach "Transkription starten": Info-Screen
  - [ ] "Deine Transkriptions-Jobs wurden gestartet. Wir senden dir eine Notification wenn sie fertig sind."
  - [ ] Button: "Zum Dashboard"
- [ ] Background-Processing (Queue-System):
  - [ ] Jobs werden zu Queue hinzugef√ºgt (Redis Queue / BullMQ)
  - [ ] Worker verarbeiten Jobs parallel
  - [ ] Status-Updates in Database
- [ ] Notification bei Completion:
  - [ ] In-App-Notification: "Transkription f√ºr Projekt [X] abgeschlossen!"
  - [ ] Optional: Email-Notification
  - [ ] Link zu Ergebnissen (PROJ-8)

### Job Status & Error Handling
- [ ] Status-Types:
  - [ ] `queued` - Job wartet in Queue
  - [ ] `processing` - API-Request l√§uft
  - [ ] `completed` - Erfolgreich
  - [ ] `failed` - Fehler aufgetreten
  - [ ] `cancelled` - User hat Job abgebrochen
- [ ] Error-Details bei `failed`:
  - [ ] Error-Type: "API Error", "Quota Exceeded", "Invalid Audio", "Timeout"
  - [ ] Error-Message: Provider-spezifische Error-Message
  - [ ] Retry-Button: "Erneut versuchen" (nur f√ºr transiente Errors wie Timeout)
- [ ] Failed Jobs beeinflussen nicht andere Jobs (isoliert)

### Provider-spezifische Implementation

#### OpenAI Whisper
- [ ] API: POST /v1/audio/transcriptions
- [ ] Model: whisper-1
- [ ] Features: Timestamps (word/segment), Language, Prompt (optional)
- [ ] Response-Format: JSON with timestamps

#### AssemblyAI
- [ ] API: POST /v2/upload ‚Üí POST /v2/transcript
- [ ] Models: best, nano
- [ ] Features: Speaker Diarization, Word-Level Timestamps, Confidence, Auto Chapters
- [ ] Polling: GET /v2/transcript/{id} alle 3 Sekunden

#### Google Speech-to-Text
- [ ] API: POST /v1/speech:longrunningrecognize
- [ ] Models: latest_long, latest_short
- [ ] Features: Speaker Diarization, Word-Level Timestamps, Confidence
- [ ] Polling: GET /v1/operations/{name}

#### AWS Transcribe
- [ ] API: StartTranscriptionJob
- [ ] Features: Speaker Identification, Timestamps, Confidence
- [ ] Polling: GetTranscriptionJob

#### ElevenLabs, Deepgram, Gladia, Speechmatics
- [ ] Analog zu oben, jeweils mit Provider-spezifischer API-Dokumentation
- [ ] Unified Response-Format: Alle Provider-Responses werden in einheitliches Schema konvertiert

#### OpenRouter
- [ ] API: POST /api/v1/audio/transcriptions
- [ ] Models: Zugang zu verschiedenen STT-Models (Whisper, etc.)
- [ ] Features: Abh√§ngig vom gew√§hlten Model (Timestamps, Language)
- [ ] Vorteil: Fallback-Option wenn ein Provider down ist, Zugang zu mehreren Models √ºber eine API

### Unified Transcript Schema
```json
{
  "provider": "openai-whisper",
  "status": "completed",
  "duration_seconds": 125.4,
  "language": "de",
  "transcript_text": "Vollst√§ndiger Text...",
  "segments": [
    {
      "start": 0.0,
      "end": 3.5,
      "text": "Hallo, wie geht es dir?",
      "confidence": 0.95,
      "speaker": "Speaker 1" // nur wenn Diarization aktiv
    }
  ],
  "metadata": {
    "processing_time_ms": 4532,
    "word_count": 342,
    "cost_usd": 0.15 // optional
  }
}
```

## Edge Cases

### API-Key Edge Cases
- **User startet Job ohne API-Key**: Error "Bitte hinterlege einen API-Key f√ºr [Provider]"
- **API-Key ung√ºltig w√§hrend Job**: Job schl√§gt fehl mit Error "API-Key ung√ºltig"
- **User √§ndert API-Key w√§hrend laufendem Job**: Laufender Job nutzt alten Key (bis Completion)
- **API-Key Quota exceeded**: Error "Provider-Quota √ºberschritten. Bitte pr√ºfe dein Account-Limit."

### Processing Edge Cases
- **Provider-API down/Timeout**: Retry-Logic (max 3 Retries mit Exponential Backoff), dann Status: "failed"
- **User bricht Job ab w√§hrend Processing**: API-Request wird gecancelled (falls Provider Cancel-API hat), Status: "cancelled"
- **Audio-File zu gro√ü f√ºr Provider (> Max-Size)**: Error "Audio-File zu gro√ü f√ºr [Provider]. Max. X MB."
- **Provider unterst√ºtzt Language nicht**: Warning "Provider [X] unterst√ºtzt Sprache [Y] nicht optimal. Ergebnis kann schlechter sein."
- **Alle Jobs schlagen fehl**: Error-Screen "Alle Transkriptions-Jobs fehlgeschlagen. Bitte pr√ºfe deine API-Keys und Audio-File."

### Feature-Support Edge Cases
- **User aktiviert Speaker Diarization f√ºr Mono-File**: Warning "Speaker Diarization funktioniert besser mit Stereo-Audio"
- **Provider unterst√ºtzt Feature nicht**: Feature wird disabled (grayed out) mit Info-Text "Nicht unterst√ºtzt von [Provider]"
- **User w√§hlt 9 Provider, 3 unterst√ºtzen Diarization nicht**: Jobs laufen trotzdem, Transkripte ohne Diarization f√ºr diese 3

### Cost Edge Cases
- **Cost Estimation fehlschl√§gt (Provider-API unreachable)**: Zeige "Kosten unbekannt"
- **Tats√§chliche Kosten weichen von Estimation ab**: Zeige tats√§chliche Kosten nach Job-Completion (falls Provider das zur√ºckgibt)

### Parallel Processing Edge Cases
- **User startet 9 Jobs gleichzeitig, Server-Kapazit√§t begrenzt**: Queue-System verarbeitet Jobs nacheinander (FIFO)
- **User startet mehrere Projekte parallel**: Alle Jobs werden zur Queue hinzugef√ºgt, Worker verarbeiten parallel (global max concurrent Jobs: z.B. 10)

## Technische Anforderungen

### Performance
- API-Request-Timeout: 60 Sekunden (dann Retry)
- Polling-Interval: 3-5 Sekunden (abh√§ngig von Provider)
- Max Concurrent Jobs pro User: 9 (1 pro Provider)
- Queue-Worker: Min 2 Worker (f√ºr Redundanz)

### Security
- API-Keys: Encrypted at-rest (AES-256-GCM)
- API-Keys: Never logged oder in Error-Messages exposed
- HTTPS-only f√ºr alle Provider-API-Requests
- Rate Limiting: Max 100 Jobs pro User pro Tag (verhindert Abuse)

### Queue-System
- Queue: Redis-basiert (BullMQ oder Bee-Queue)
- Job-Retry: Max 3 Retries bei transienten Errors
- Job-TTL: 24 Stunden (nach 24h wird Job automatisch gecancelled)
- Dead Letter Queue: Failed Jobs nach 3 Retries

### Error Handling & Logging
- Log alle API-Requests (Provider, Status, Duration, Error)
- Log API-Key-Validierungen (Success/Failure ohne Key-Content)
- Alert bei ungew√∂hnlich hoher Failure-Rate (> 30% pro Provider)
- Sentry/Error-Tracking f√ºr Exception-Monitoring

### Provider-Adapter Pattern
```typescript
interface TranscriptionProvider {
  name: string;
  validateApiKey(apiKey: string): Promise<boolean>;
  transcribe(audioFile: File, config: TranscriptionConfig): Promise<Job>;
  getJobStatus(jobId: string): Promise<JobStatus>;
  cancelJob(jobId: string): Promise<void>;
  parseResponse(rawResponse: any): UnifiedTranscript;
}
```
- Jeder Provider implementiert dieses Interface
- Unified API f√ºr Backend-Logic
- Provider-spezifische Details sind abstrahiert

## Abh√§ngigkeiten
- **PROJ-6** (Audio Upload) - ben√∂tigt hochgeladene Audio-Files
- **PROJ-1** (Auth) - User muss eingeloggt sein
- **PROJ-9** (Projekt-Management) - Jobs geh√∂ren zu Projekten

## Abh√§ngig von diesem Feature
- **PROJ-8** (Vergleich UI) - zeigt Transkriptions-Ergebnisse

## Tech Stack Vorschl√§ge (f√ºr Solution Architect)
- Queue: BullMQ (Redis-basiert, robustes Retry-Handling)
- API-Clients: Axios (HTTP-Requests), Provider-spezifische SDKs (falls verf√ºgbar)
- Encryption: `crypto` (Node.js native) f√ºr AES-256-GCM
- Progress-Tracking: Server-Sent Events (SSE) oder WebSockets
- Job-Storage: PostgreSQL (Job-Metadaten, Status) + Redis (Queue)

## Provider-Dokumentation Links (f√ºr Developer)
- OpenAI Whisper: https://platform.openai.com/docs/guides/speech-to-text
- AssemblyAI: https://www.assemblyai.com/docs
- Google Speech-to-Text: https://cloud.google.com/speech-to-text/docs
- AWS Transcribe: https://docs.aws.amazon.com/transcribe
- ElevenLabs: https://elevenlabs.io/docs/api-reference/text-to-speech
- Deepgram: https://developers.deepgram.com/docs
- Gladia: https://docs.gladia.io/
- Speechmatics: https://docs.speechmatics.com/
- OpenRouter: https://openrouter.ai/docs

## User Experience Hinweise
- **Provider-Auswahl**: Zeige welche Provider User bereits konfiguriert haben (gr√ºner Haken)
- **Progress-Feedback**: User muss sehen was passiert (nicht einfach warten)
- **Clear Errors**: Provider-spezifische Errors √ºbersetzen in User-freundliche Messages
- **Cost Transparency**: Zeige gesch√§tzte Kosten VOR Job-Start (verhindert teure √úberraschungen)
- **Retry-Option**: Bei transienten Errors "Erneut versuchen" anbieten
